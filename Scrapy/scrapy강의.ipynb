{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <스크래피>\n",
    "- 데이터 크롤링 프레임워크\n",
    "- 조금 무거운 편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. cmd창에서 설치\n",
    "- pip install scrapy\n",
    "- pip install scrapyd\n",
    "- pip install scrapyd-client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. cmd에서 scrapy 설치 경로\n",
    "- C:\\Users\\User\\scrapy_naver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. 내컴퓨터 -> 속성 -> 고급시스템설정 -> 환경변수path -> 추가\n",
    "- C:\\Users\\User\\anaconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. vscode cmd에서 수행\n",
    "- 4-1. conda activate base  # 가상 환경 이름이 'base'라고 가정 (or 자동생성)\n",
    "- 4-2. conda create -n scrapy python=3.8 # 가상환경 생성\n",
    "- 4-2. conda info --envs # 가상환경 생성 확인\n",
    "- 4-2. conda activate scrapy # 가상환경 실행\n",
    "- 4-3. cd C:\\Users\\User\\scrapy_naver\n",
    "- 4-4. scrapy runspider scrapy_naver/spiders/news.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. vscode cmd에서 크롤링 작업 수행\n",
    "- ! 코드 작성 후 실행 할 때, 작업 내용 save 반드시 수행 !\n",
    "- 5-1. scrapy crawl news -a date=20231113\n",
    "- 5-2. scrapy crawl news -O news.json -a date=20231113 # 영문\n",
    "- 5-3. scrapyd-deploy # 코드 변경 마다 배포 해줘야 함\n",
    "- 5-4. pip install pywin32설치 -> scrapyd(오픈API에게 크롤링 요청하는 기능)껐다 키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
